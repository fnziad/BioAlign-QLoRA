{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0b5fdac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading raw file: data/raw/CTD_curated_genes_diseases.csv\n",
      "Loaded data with 34222 rows and columns: ['GeneSymbol', 'GeneID', 'DiseaseName', 'DiseaseID', 'DirectEvidence', 'OmimIDs', 'PubMedIDs']\n",
      "Dropped 0 rows with missing gene/disease\n",
      "Evidence filter ON: keeping 34222 rows matching keywords ['marker/mechanism', 'therapeutic']\n",
      "Positive pairs: 34222\n",
      "Sampling 34222 negative examples (neg ratio=1)\n",
      "Negative pairs sampled: 34222\n",
      "Total dataset size (pos+neg): 68444\n",
      "Negative pairs sampled: 34222\n",
      "Total dataset size (pos+neg): 68444\n",
      "Saved: data/processed/gd_pairs.csv\n",
      "Saved pair-level splits: train: 54755  test: 13689\n",
      "Entity-held-out: 911 genes held out, 585 diseases held out\n",
      "Entity-held splits: train: 56298  test: 12146\n",
      "Saved: data/processed/gd_pairs.csv\n",
      "Saved pair-level splits: train: 54755  test: 13689\n",
      "Entity-held-out: 911 genes held out, 585 diseases held out\n",
      "Entity-held splits: train: 56298  test: 12146\n",
      "Done. Outputs in: data/processed\n",
      "Done. Outputs in: data/processed\n"
     ]
    }
   ],
   "source": [
    "# src/data_prep.py\n",
    "\"\"\"\n",
    "Data prep for CTD curated gene-disease associations.\n",
    "Outputs:\n",
    "- data/processed/gd_pairs.csv  (positives + negatives)\n",
    "- data/processed/train_pairs.csv, test_pairs.csv (pair-level)\n",
    "- data/processed/train_entityheld.csv, test_entityheld.csv (entity-held-out)\n",
    "- data/processed/genes.csv, diseases.csv\n",
    "\"\"\"\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ========== USER CONFIG ==========\n",
    "RAW_PATH = \"data/raw/CTD_curated_genes_diseases.csv\"   # change if needed\n",
    "OUT_DIR = \"data/processed\"\n",
    "SEED = 42\n",
    "NEG_RATIO = 1        # negatives per positive (1 = balanced)\n",
    "EVIDENCE_FILTER = True   # set False to use all rows\n",
    "EVIDENCE_KEYWORDS = [\"marker/mechanism\", \"therapeutic\"]  # keep rows that match any\n",
    "HOLDOUT_FRACTION = 0.10  # for entity-held-out\n",
    "MAX_NEG_ATTEMPTS = 100000\n",
    "# =================================\n",
    "\n",
    "rng = np.random.default_rng(SEED)\n",
    "Path(OUT_DIR).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# --- 1. Load CSV robustly ---\n",
    "print(\"Loading raw file:\", RAW_PATH)\n",
    "# CTD files have comment lines starting with #, and the header is in a comment\n",
    "# The actual data starts without a header, so we need to specify column names\n",
    "try:\n",
    "    # First, try reading with comment skip and no header, then assign column names\n",
    "    df = pd.read_csv(RAW_PATH, comment='#', header=None)\n",
    "    df.columns = ['GeneSymbol','GeneID','DiseaseName','DiseaseID','DirectEvidence','OmimIDs','PubMedIDs']\n",
    "except Exception as e:\n",
    "    print(f\"Error reading with comment skip: {e}\")\n",
    "    # fallback: manually find where data starts\n",
    "    with open(RAW_PATH, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    # find first non-comment line\n",
    "    data_start = 0\n",
    "    for i, line in enumerate(lines):\n",
    "        if not line.strip().startswith('#') and line.strip():\n",
    "            data_start = i\n",
    "            break\n",
    "    \n",
    "    # read from data start without header\n",
    "    df = pd.read_csv(RAW_PATH, skiprows=data_start, header=None)\n",
    "    df.columns = ['GeneSymbol','GeneID','DiseaseName','DiseaseID','DirectEvidence','OmimIDs','PubMedIDs']\n",
    "\n",
    "print(f\"Loaded data with {len(df)} rows and columns: {df.columns.tolist()}\")\n",
    "\n",
    "# normalize column names\n",
    "cols = [c.strip() for c in df.columns]\n",
    "df.columns = cols\n",
    "\n",
    "# Basic check: required columns\n",
    "required = ['GeneSymbol','DiseaseName']\n",
    "for r in required:\n",
    "    if r not in df.columns:\n",
    "        raise ValueError(f\"Required column '{r}' not found in data. Found columns: {df.columns.tolist()}\")\n",
    "\n",
    "# --- 2. Clean text fields ---\n",
    "df['GeneSymbol'] = df['GeneSymbol'].astype(str).str.strip()\n",
    "df['DiseaseName'] = df['DiseaseName'].astype(str).str.strip()\n",
    "# ensure PubMedIDs column exists\n",
    "if 'PubMedIDs' not in df.columns:\n",
    "    df['PubMedIDs'] = \"\"\n",
    "\n",
    "# drop missing\n",
    "n_before = len(df)\n",
    "df = df[ (~df['GeneSymbol'].isna()) & (~df['DiseaseName'].isna()) ]\n",
    "print(f\"Dropped {n_before - len(df)} rows with missing gene/disease\")\n",
    "\n",
    "# --- 3. Optional: evidence filtering for higher confidence ---\n",
    "if EVIDENCE_FILTER and 'DirectEvidence' in df.columns:\n",
    "    mask = df['DirectEvidence'].fillna(\"\").str.lower().apply(\n",
    "        lambda s: any(k.lower() in s for k in EVIDENCE_KEYWORDS)\n",
    "    )\n",
    "    n_keep = mask.sum()\n",
    "    print(f\"Evidence filter ON: keeping {n_keep} rows matching keywords {EVIDENCE_KEYWORDS}\")\n",
    "    df = df[mask].copy()\n",
    "else:\n",
    "    print(\"Evidence filter OFF or DirectEvidence missing; using full dataset\")\n",
    "\n",
    "# --- 4. Build positive sentences and dedupe ---\n",
    "df['text'] = df['GeneSymbol'] + \" is associated with \" + df['DiseaseName']\n",
    "pos_df = df[['GeneSymbol','DiseaseName','text','PubMedIDs']].drop_duplicates().reset_index(drop=True)\n",
    "pos_df['label'] = 1\n",
    "print(\"Positive pairs:\", len(pos_df))\n",
    "\n",
    "# --- 5. Negative sampling (random) ---\n",
    "genes = pos_df['GeneSymbol'].unique()\n",
    "diseases = pos_df['DiseaseName'].unique()\n",
    "pos_text_set = set(pos_df['text'].tolist())\n",
    "\n",
    "negatives = []\n",
    "attempts = 0\n",
    "target_neg = len(pos_df) * NEG_RATIO\n",
    "print(f\"Sampling {target_neg} negative examples (neg ratio={NEG_RATIO})\")\n",
    "while len(negatives) < target_neg and attempts < MAX_NEG_ATTEMPTS:\n",
    "    g = rng.choice(genes)\n",
    "    d = rng.choice(diseases)\n",
    "    txt = f\"{g} is associated with {d}\"\n",
    "    if txt not in pos_text_set:\n",
    "        negatives.append((g,d,txt))\n",
    "    attempts += 1\n",
    "\n",
    "neg_df = pd.DataFrame(negatives, columns=['GeneSymbol','DiseaseName','text'])\n",
    "neg_df['label'] = 0\n",
    "neg_df['PubMedIDs'] = \"\"  # no pmid for synthetic negatives\n",
    "print(\"Negative pairs sampled:\", len(neg_df))\n",
    "\n",
    "# Optional: create some hard negatives (same gene but slightly related diseases)\n",
    "# (LEFT AS TODO for team if they have disease categories)\n",
    "\n",
    "# --- 6. Combine, shuffle, save master pairs file ---\n",
    "all_df = pd.concat([pos_df[['GeneSymbol','DiseaseName','text','PubMedIDs','label']], neg_df], ignore_index=True)\n",
    "all_df = all_df.sample(frac=1, random_state=SEED).reset_index(drop=True)\n",
    "print(\"Total dataset size (pos+neg):\", len(all_df))\n",
    "all_df.to_csv(os.path.join(OUT_DIR, \"gd_pairs.csv\"), index=False)\n",
    "print(\"Saved:\", os.path.join(OUT_DIR, \"gd_pairs.csv\"))\n",
    "\n",
    "# --- 7. Train/test split (pair-level stratified by label) ---\n",
    "train, test = train_test_split(all_df, test_size=0.2, stratify=all_df['label'], random_state=SEED)\n",
    "train.to_csv(os.path.join(OUT_DIR, \"train_pairs.csv\"), index=False)\n",
    "test.to_csv(os.path.join(OUT_DIR, \"test_pairs.csv\"), index=False)\n",
    "print(\"Saved pair-level splits: train:\", len(train), \" test:\", len(test))\n",
    "\n",
    "# --- 8. Entity-held-out split (hold out some genes and diseases) ---\n",
    "unique_genes = list(genes)\n",
    "unique_diseases = list(diseases)\n",
    "n_g_hold = max(1, int(len(unique_genes) * HOLDOUT_FRACTION))\n",
    "n_d_hold = max(1, int(len(unique_diseases) * HOLDOUT_FRACTION))\n",
    "genes_hold = list(rng.choice(unique_genes, size=n_g_hold, replace=False))\n",
    "diseases_hold = list(rng.choice(unique_diseases, size=n_d_hold, replace=False))\n",
    "print(\"Entity-held-out:\", len(genes_hold), \"genes held out,\", len(diseases_hold), \"diseases held out\")\n",
    "\n",
    "# test set = rows where gene in genes_hold or disease in diseases_hold\n",
    "ent_test_mask = all_df['GeneSymbol'].isin(genes_hold) | all_df['DiseaseName'].isin(diseases_hold)\n",
    "ent_test = all_df[ent_test_mask]\n",
    "ent_train = all_df[~ent_test_mask]\n",
    "print(\"Entity-held splits: train:\", len(ent_train), \" test:\", len(ent_test))\n",
    "ent_train.to_csv(os.path.join(OUT_DIR, \"train_entityheld.csv\"), index=False)\n",
    "ent_test.to_csv(os.path.join(OUT_DIR, \"test_entityheld.csv\"), index=False)\n",
    "\n",
    "# --- 9. Save entities lists and mapping for later KG building ---\n",
    "genes_df = pd.DataFrame({'GeneSymbol': sorted(list(genes))})\n",
    "diseases_df = pd.DataFrame({'DiseaseName': sorted(list(diseases))})\n",
    "genes_df.to_csv(os.path.join(OUT_DIR, \"genes.csv\"), index=False)\n",
    "diseases_df.to_csv(os.path.join(OUT_DIR, \"diseases.csv\"), index=False)\n",
    "\n",
    "meta = {\n",
    "    \"n_pos\": int(pos_df.shape[0]),\n",
    "    \"n_neg\": int(neg_df.shape[0]),\n",
    "    \"total\": int(all_df.shape[0]),\n",
    "    \"holdout_genes\": genes_hold,\n",
    "    \"holdout_diseases\": diseases_hold,\n",
    "    \"seed\": int(SEED)\n",
    "}\n",
    "with open(os.path.join(OUT_DIR, \"prep_metadata.json\"), \"w\") as f:\n",
    "    json.dump(meta, f, indent=2)\n",
    "\n",
    "print(\"Done. Outputs in:\", OUT_DIR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
